# ğŸ“§ Spam Detector con Machine Learning

Este proyecto tiene como objetivo la detecciÃ³n automÃ¡tica de mensajes **spam** utilizando algoritmos de aprendizaje automÃ¡tico. EstÃ¡ dividido en dos fases principales: anÃ¡lisis exploratorio y desarrollo de un modelo de clasificaciÃ³n.

## ğŸ§  DescripciÃ³n general

Utilizamos el dataset **SMS Spam Collection**, que contiene 5,572 mensajes etiquetados como "ham" (no spam) o "spam". A partir de estos datos, se realiza un anÃ¡lisis exhaustivo seguido de la construcciÃ³n y evaluaciÃ³n de un modelo de clasificaciÃ³n binaria.

---

## ğŸ§© Parte I â€” AnÃ¡lisis Exploratorio

**Notebook:** `ProyectoDSParteI+TuApellido.ipynb`

- Limpieza de datos (valores nulos, duplicados, outliers)
- Visualizaciones univariadas, bivariadas y multivariadas
- FormulaciÃ³n de hipÃ³tesis:
  - Los mensajes spam tienden a ser mÃ¡s largos.
  - Palabras como â€œwinâ€, â€œfreeâ€, â€œcashâ€ aparecen mÃ¡s en spam.
  - Los mensajes spam tienen mÃ¡s signos de exclamaciÃ³n o letras mayÃºsculas.
- AnÃ¡lisis estadÃ­stico descriptivo
- DetecciÃ³n de valores faltantes

---

## ğŸ¤– Parte II â€” ClasificaciÃ³n con Machine Learning

**Notebook:** `ProyectoParteIII+TuApellido.ipynb`

### âœ”ï¸ Objetivo

Desarrollar y evaluar un modelo de clasificaciÃ³n que determine si un mensaje es spam o no.

### ğŸ§± Etapas realizadas

- **VectorizaciÃ³n de texto:** mediante `TF-IDF`
- **SelecciÃ³n de caracterÃ­sticas:** usando Chi-cuadrado (`chi2`) con `SelectKBest`
- **Modelos evaluados:**
  - `Multinomial Naive Bayes` (modelo principal)
  - ComparaciÃ³n opcional con `KNN` u otros clasificadores
- **EvaluaciÃ³n:**
  - `Accuracy`, `Precision`, `Recall`, `F1-Score`
  - `Matriz de confusiÃ³n`
  - InterpretaciÃ³n de resultados

### âœ… Resultado

El modelo basado en **Naive Bayes** logrÃ³ una alta precisiÃ³n en la detecciÃ³n de mensajes spam, siendo mÃ¡s eficiente que otros enfoques como KNN debido a la naturaleza textual y dispersa del dataset.

## ğŸ¤” Â¿Por quÃ© se usa Naive Bayes y no KNN?

### âœ… Ventajas de Naive Bayes:

- Es un modelo **probabilÃ­stico** especialmente eficaz para datos de texto.
- Funciona muy bien con datos **altamente dispersos** como los generados por TF-IDF.
- Tiene un **entrenamiento y predicciÃ³n muy rÃ¡pidos**, ideal para grandes volÃºmenes de texto.
- Requiere poca configuraciÃ³n y es **robusto al ruido** en el texto.

### âš ï¸ Desventajas de KNN para este caso:

- KNN es un **modelo basado en distancias**, lo que lo vuelve ineficiente para datos de texto (alta dimensionalidad).
- Requiere comparar cada nuevo mensaje con **todo el dataset**, lo cual **ralentiza la predicciÃ³n**.
- Es **sensible a outliers** y **no escala bien** en tareas de clasificaciÃ³n textual.

### ğŸ§  ConclusiÃ³n:

> En tareas de clasificaciÃ³n de texto como detecciÃ³n de spam, **Naive Bayes es mÃ¡s eficiente, preciso y adecuado que KNN**, y es una de las elecciones clÃ¡sicas para este tipo de problemas.

---

## ğŸ“ Estructura del proyecto

ğŸ“¦ spam-detector
â”£ ğŸ“„ ProyectoDSParteI+TuApellido.ipynb
â”£ ğŸ“„ ProyectoParteIII+TuApellido.ipynb
â”£ ğŸ“„ README.md
â”— ğŸ“‚ data
â”— ğŸ“„ ham-spam.csv
â”— ğŸ“„ sms.tsv

## ğŸ”§ Requisitos

- Python 3.8+
- LibrerÃ­as:
  - `pandas`
  - `scikit-learn`
  - `seaborn`
  - `matplotlib`

```bash
pip install pandas scikit-learn seaborn matplotlib
```
